{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook de funções comuns (Exemplo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr, current_timestamp\n",
    "\n",
    "def adicionar_data_de_ingestao(df, nome_coluna='data_de_ingestao', add_tempo=0, incluir_hora=False, unidade_de_medida='horas'):\n",
    "\n",
    "    \"\"\"\n",
    "    Função para adicionar coluna de data de ingestão do arquivo em formato timestamp ou date.\n",
    "\n",
    "    Parâmetros:\n",
    "\n",
    "        df : Dataframe que será alterado.\n",
    "        nome_coluna : Nome da coluna que será gerada. Padrão: 'data_de_ingestao'.\n",
    "        add_tempo : Quantidade de tempo que será adicionado ou retirado do timestamp. Padrão: 0.\n",
    "        incluir_hora : Valor booleano que indica se a hora será incluida ou não. Padrão: False.\n",
    "        unidade_de_medida : Unidade de medida do tempo que será adicionado, variando entre 'horas', 'dias', 'meses' e 'anos'. Padrão: 'horas'.\n",
    "    \n",
    "    Retorna um dataframe modificado, com uma coluna de data ou timestamp adicionada.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    unidade_de_medida = unidade_de_medida.lower()  # Certificando que o param 'unidade_de_medida' esteja em lowercase\n",
    "    sinal_operacao = '-' if add_tempo < 0 else '+'  # Verificando o sinal de operação baseado no param 'add_tempo'\n",
    "    add_tempo = add_tempo*-1 if add_tempo < 0 else add_tempo  # Convertendo para positivo se o param 'add_tempo' for negativo\n",
    "\n",
    "    df = df.withColumn(nome_coluna, current_timestamp())\n",
    "    \n",
    "    if incluir_hora:\n",
    "        if unidade_de_medida == 'horas':\n",
    "            df = df.withColumn(nome_coluna, expr(f'{nome_coluna} {sinal_operacao} INTERVAL {add_tempo} HOURS'))\n",
    "        elif unidade_de_medida == 'dias':\n",
    "            df = df.withColumn(nome_coluna, expr(f'{nome_coluna} {sinal_operacao} INTERVAL {add_tempo} DAYS'))\n",
    "        elif unidade_de_medida == 'meses':\n",
    "            df = df.withColumn(nome_coluna, expr(f'{nome_coluna} {sinal_operacao} INTERVAL {add_tempo} MONTHS'))\n",
    "        elif unidade_de_medida == 'anos':\n",
    "            df = df.withColumn(nome_coluna, expr(f'{nome_coluna} {sinal_operacao} INTERVAL {add_tempo} YEARS'))\n",
    "\n",
    "        return df\n",
    "    else:\n",
    "        from pyspark.sql.functions import date_format, col\n",
    "        \n",
    "        if unidade_de_medida == 'horas':\n",
    "            df = df.withColumn(nome_coluna, expr(f'{nome_coluna} {sinal_operacao} INTERVAL {add_tempo} HOURS'))\n",
    "        elif unidade_de_medida == 'dias':\n",
    "            df = df.withColumn(nome_coluna, expr(f'{nome_coluna} {sinal_operacao} INTERVAL {add_tempo} DAYS'))\n",
    "        elif unidade_de_medida == 'meses':\n",
    "            df = df.withColumn(nome_coluna, expr(f'{nome_coluna} {sinal_operacao} INTERVAL {add_tempo} MONTHS'))\n",
    "        elif unidade_de_medida == 'anos':\n",
    "            df = df.withColumn(nome_coluna, expr(f'{nome_coluna} {sinal_operacao} INTERVAL {add_tempo} YEARS'))\n",
    "        \n",
    "        df = df.withColumn(nome_coluna, date_format(col(nome_coluna), \"yyyy-MM-dd\")) \\\n",
    "               .withColumn(nome_coluna, col(nome_coluna).cast('date'))\n",
    "\n",
    "        return df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
